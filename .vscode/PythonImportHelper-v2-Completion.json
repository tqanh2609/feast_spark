[
    {
        "label": "timedelta",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "datetime",
        "importPath": "datetime",
        "description": "datetime",
        "isExtraImport": true,
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "Entity",
        "importPath": "feast",
        "description": "feast",
        "isExtraImport": true,
        "detail": "feast",
        "documentation": {}
    },
    {
        "label": "FeatureService",
        "importPath": "feast",
        "description": "feast",
        "isExtraImport": true,
        "detail": "feast",
        "documentation": {}
    },
    {
        "label": "FeatureView",
        "importPath": "feast",
        "description": "feast",
        "isExtraImport": true,
        "detail": "feast",
        "documentation": {}
    },
    {
        "label": "Field",
        "importPath": "feast",
        "description": "feast",
        "isExtraImport": true,
        "detail": "feast",
        "documentation": {}
    },
    {
        "label": "FeatureStore",
        "importPath": "feast",
        "description": "feast",
        "isExtraImport": true,
        "detail": "feast",
        "documentation": {}
    },
    {
        "label": "FeatureStore",
        "importPath": "feast",
        "description": "feast",
        "isExtraImport": true,
        "detail": "feast",
        "documentation": {}
    },
    {
        "label": "SparkSource",
        "importPath": "feast.infra.offline_stores.contrib.spark_offline_store.spark_source",
        "description": "feast.infra.offline_stores.contrib.spark_offline_store.spark_source",
        "isExtraImport": true,
        "detail": "feast.infra.offline_stores.contrib.spark_offline_store.spark_source",
        "documentation": {}
    },
    {
        "label": "Float32",
        "importPath": "feast.types",
        "description": "feast.types",
        "isExtraImport": true,
        "detail": "feast.types",
        "documentation": {}
    },
    {
        "label": "Int64",
        "importPath": "feast.types",
        "description": "feast.types",
        "isExtraImport": true,
        "detail": "feast.types",
        "documentation": {}
    },
    {
        "label": "SparkSession",
        "importPath": "pyspark.sql",
        "description": "pyspark.sql",
        "isExtraImport": true,
        "detail": "pyspark.sql",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pyspark.sql.functions",
        "description": "pyspark.sql.functions",
        "isExtraImport": true,
        "detail": "pyspark.sql.functions",
        "documentation": {}
    },
    {
        "label": "col",
        "importPath": "pyspark.sql.functions",
        "description": "pyspark.sql.functions",
        "isExtraImport": true,
        "detail": "pyspark.sql.functions",
        "documentation": {}
    },
    {
        "label": "*",
        "importPath": "pyspark.sql.types",
        "description": "pyspark.sql.types",
        "isExtraImport": true,
        "detail": "pyspark.sql.types",
        "documentation": {}
    },
    {
        "label": "StorageLevel",
        "importPath": "pyspark",
        "description": "pyspark",
        "isExtraImport": true,
        "detail": "pyspark",
        "documentation": {}
    },
    {
        "label": "subprocess",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "subprocess",
        "description": "subprocess",
        "detail": "subprocess",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "pandas",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "pandas",
        "description": "pandas",
        "detail": "pandas",
        "documentation": {}
    },
    {
        "label": "os",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "os",
        "description": "os",
        "detail": "os",
        "documentation": {}
    },
    {
        "label": "PushMode",
        "importPath": "feast.data_source",
        "description": "feast.data_source",
        "isExtraImport": true,
        "detail": "feast.data_source",
        "documentation": {}
    },
    {
        "label": "PushMode",
        "importPath": "feast.data_source",
        "description": "feast.data_source",
        "isExtraImport": true,
        "detail": "feast.data_source",
        "documentation": {}
    },
    {
        "label": "CURRENT_DIR",
        "kind": 5,
        "importPath": "example_repo",
        "description": "example_repo",
        "peekOfCode": "CURRENT_DIR = Path(__file__).parent\n# Entity definitions\ndriver = Entity(\n    name=\"driver\",\n    description=\"driver id\",\n)\ncustomer = Entity(\n    name=\"customer\",\n    description=\"customer id\",\n)",
        "detail": "example_repo",
        "documentation": {}
    },
    {
        "label": "driver",
        "kind": 5,
        "importPath": "example_repo",
        "description": "example_repo",
        "peekOfCode": "driver = Entity(\n    name=\"driver\",\n    description=\"driver id\",\n)\ncustomer = Entity(\n    name=\"customer\",\n    description=\"customer id\",\n)\n# Sources\ndriver_hourly_stats = SparkSource(",
        "detail": "example_repo",
        "documentation": {}
    },
    {
        "label": "customer",
        "kind": 5,
        "importPath": "example_repo",
        "description": "example_repo",
        "peekOfCode": "customer = Entity(\n    name=\"customer\",\n    description=\"customer id\",\n)\n# Sources\ndriver_hourly_stats = SparkSource(\n    name=\"driver_hourly_stats\",\n    table=\"thidiemcatalog.testthidiem.driver_hourly_stats\",\n    timestamp_field=\"event_timestamp\",\n    created_timestamp_column=\"created\",",
        "detail": "example_repo",
        "documentation": {}
    },
    {
        "label": "driver_hourly_stats",
        "kind": 5,
        "importPath": "example_repo",
        "description": "example_repo",
        "peekOfCode": "driver_hourly_stats = SparkSource(\n    name=\"driver_hourly_stats\",\n    table=\"thidiemcatalog.testthidiem.driver_hourly_stats\",\n    timestamp_field=\"event_timestamp\",\n    created_timestamp_column=\"created\",\n)\n# customer_daily_profile = SparkSource(\n#     name=\"customer_daily_profile\",\n#     table=\"thidiemcatalog.testthidiem.customer_daily_profile\",\n#     timestamp_field=\"event_timestamp\",",
        "detail": "example_repo",
        "documentation": {}
    },
    {
        "label": "driver_hourly_stats_view",
        "kind": 5,
        "importPath": "example_repo",
        "description": "example_repo",
        "peekOfCode": "driver_hourly_stats_view = FeatureView(\n    name=\"driver_hourly_stats\",\n    entities=[driver],\n    ttl=timedelta(days=7),\n    schema=[\n        Field(name=\"conv_rate\", dtype=Float32),\n        Field(name=\"acc_rate\", dtype=Float32),\n        Field(name=\"avg_daily_trips\", dtype=Int64),\n    ],\n    online=True,",
        "detail": "example_repo",
        "documentation": {}
    },
    {
        "label": "driver_stats_fs",
        "kind": 5,
        "importPath": "example_repo",
        "description": "example_repo",
        "peekOfCode": "driver_stats_fs = FeatureService(\n    name=\"driver_activity\",\n    features=[driver_hourly_stats_view],\n)\n# customer_daily_profile_view",
        "detail": "example_repo",
        "documentation": {}
    },
    {
        "label": "fetch_historical_features_entity_df",
        "kind": 2,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "def fetch_historical_features_entity_df(store: FeatureStore, for_batch_scoring: bool):\n    # Note: see https://docs.feast.dev/getting-started/concepts/feature-retrieval for more details on how to retrieve\n    # for all entities in the offline store instead\n    entity_df = pd.DataFrame.from_dict(\n        {\n            # entity's join key -> entity values\n            \"driver_id\": [1001, 1002, 1003],\n            # \"event_timestamp\" (reserved key) -> timestamps\n            \"event_timestamp\": [\n                datetime(2021, 4, 12, 10, 59, 42),",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "fetch_online_features",
        "kind": 2,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "def fetch_online_features(store, use_feature_service: bool):\n    entity_rows = [\n        # {join_key: entity_value}\n        {\n            \"driver_id\": 1001,\n            \"val_to_add\": 1000,\n            \"val_to_add_2\": 2000,\n        },\n        {\n            \"driver_id\": 1002,",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "packages",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "packages = [\n    \"feast\",\n    \"feast[spark]\",\n    \"feast[singlestore]\",\n    \"pyarrow==19.0.1\"\n]\n# Construct the pip install command\ncommand = [sys.executable, \"-m\", \"pip\", \"install\"] + packages\n# Execute the command\nsubprocess.check_call(command)",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "command",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "command = [sys.executable, \"-m\", \"pip\", \"install\"] + packages\n# Execute the command\nsubprocess.check_call(command)\n# client\nwxd_hms_username = 'devadmin'\nwxd_hms_password = 'AX2Z1MBUoOergIb'\n# landingdev\niceberg_catalog = \"thidiemcatalog\"\naccess_key = \"WEeGX66cjJBVgira3DcU\"\nsecret_key = \"BgbbrH08yKFcM4rz1RPUlRxWn3yuMV46W1nE0uTO\"",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "wxd_hms_username",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "wxd_hms_username = 'devadmin'\nwxd_hms_password = 'AX2Z1MBUoOergIb'\n# landingdev\niceberg_catalog = \"thidiemcatalog\"\naccess_key = \"WEeGX66cjJBVgira3DcU\"\nsecret_key = \"BgbbrH08yKFcM4rz1RPUlRxWn3yuMV46W1nE0uTO\"\nbucket_name = \"thidiem\"\nhivemetastore_host = \"thrift://ibm-lh-lakehouse-hive-metastore-svc.zen.svc.cluster.local:9083\"\ns3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "wxd_hms_password",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "wxd_hms_password = 'AX2Z1MBUoOergIb'\n# landingdev\niceberg_catalog = \"thidiemcatalog\"\naccess_key = \"WEeGX66cjJBVgira3DcU\"\nsecret_key = \"BgbbrH08yKFcM4rz1RPUlRxWn3yuMV46W1nE0uTO\"\nbucket_name = \"thidiem\"\nhivemetastore_host = \"thrift://ibm-lh-lakehouse-hive-metastore-svc.zen.svc.cluster.local:9083\"\ns3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\\n#             .appName(\"test\") \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "iceberg_catalog",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "iceberg_catalog = \"thidiemcatalog\"\naccess_key = \"WEeGX66cjJBVgira3DcU\"\nsecret_key = \"BgbbrH08yKFcM4rz1RPUlRxWn3yuMV46W1nE0uTO\"\nbucket_name = \"thidiem\"\nhivemetastore_host = \"thrift://ibm-lh-lakehouse-hive-metastore-svc.zen.svc.cluster.local:9083\"\ns3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\\n#             .appName(\"test\") \\\n#             .config(\"spark.datasource.singlestore.clientEndpoint\", \"192.168.0.121:32216\") \\\n#             .config(\"spark.datasource.singlestore.user\", \"admin\") \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "access_key",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "access_key = \"WEeGX66cjJBVgira3DcU\"\nsecret_key = \"BgbbrH08yKFcM4rz1RPUlRxWn3yuMV46W1nE0uTO\"\nbucket_name = \"thidiem\"\nhivemetastore_host = \"thrift://ibm-lh-lakehouse-hive-metastore-svc.zen.svc.cluster.local:9083\"\ns3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\\n#             .appName(\"test\") \\\n#             .config(\"spark.datasource.singlestore.clientEndpoint\", \"192.168.0.121:32216\") \\\n#             .config(\"spark.datasource.singlestore.user\", \"admin\") \\\n#             .config(\"spark.datasource.singlestore.password\", \"secretpass\") \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "secret_key",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "secret_key = \"BgbbrH08yKFcM4rz1RPUlRxWn3yuMV46W1nE0uTO\"\nbucket_name = \"thidiem\"\nhivemetastore_host = \"thrift://ibm-lh-lakehouse-hive-metastore-svc.zen.svc.cluster.local:9083\"\ns3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\\n#             .appName(\"test\") \\\n#             .config(\"spark.datasource.singlestore.clientEndpoint\", \"192.168.0.121:32216\") \\\n#             .config(\"spark.datasource.singlestore.user\", \"admin\") \\\n#             .config(\"spark.datasource.singlestore.password\", \"secretpass\") \\\n#             .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "bucket_name",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "bucket_name = \"thidiem\"\nhivemetastore_host = \"thrift://ibm-lh-lakehouse-hive-metastore-svc.zen.svc.cluster.local:9083\"\ns3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\\n#             .appName(\"test\") \\\n#             .config(\"spark.datasource.singlestore.clientEndpoint\", \"192.168.0.121:32216\") \\\n#             .config(\"spark.datasource.singlestore.user\", \"admin\") \\\n#             .config(\"spark.datasource.singlestore.password\", \"secretpass\") \\\n#             .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n#             .config(\"spark.hive.metastore.use.SSL\", \"true\") \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "hivemetastore_host",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "hivemetastore_host = \"thrift://ibm-lh-lakehouse-hive-metastore-svc.zen.svc.cluster.local:9083\"\ns3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\\n#             .appName(\"test\") \\\n#             .config(\"spark.datasource.singlestore.clientEndpoint\", \"192.168.0.121:32216\") \\\n#             .config(\"spark.datasource.singlestore.user\", \"admin\") \\\n#             .config(\"spark.datasource.singlestore.password\", \"secretpass\") \\\n#             .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n#             .config(\"spark.hive.metastore.use.SSL\", \"true\") \\\n#             .config(\"spark.hive.metastore.truststore.type\", \"JKS\") \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "s3_endpoint",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "s3_endpoint = \"https://rook-ceph-rgw.vnpt.vn\"\n# spark = SparkSession.builder \\\n#             .appName(\"test\") \\\n#             .config(\"spark.datasource.singlestore.clientEndpoint\", \"192.168.0.121:32216\") \\\n#             .config(\"spark.datasource.singlestore.user\", \"admin\") \\\n#             .config(\"spark.datasource.singlestore.password\", \"secretpass\") \\\n#             .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\") \\\n#             .config(\"spark.hive.metastore.use.SSL\", \"true\") \\\n#             .config(\"spark.hive.metastore.truststore.type\", \"JKS\") \\\n#             .config(\"spark.hive.metastore.truststore.path\", \"file:///opt/ibm/jdk/lib/security/cacerts\") \\",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "path",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "path = '/spark_job/QuangAnh/feastspark/main/'\n# Change the current working directory\nos.chdir(path)\n# Optional: Verify the change\nprint(\"Current working directory:\", os.getcwd())\ndef fetch_historical_features_entity_df(store: FeatureStore, for_batch_scoring: bool):\n    # Note: see https://docs.feast.dev/getting-started/concepts/feature-retrieval for more details on how to retrieve\n    # for all entities in the offline store instead\n    entity_df = pd.DataFrame.from_dict(\n        {",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "store",
        "kind": 5,
        "importPath": "qa_feast_spark",
        "description": "qa_feast_spark",
        "peekOfCode": "store = FeatureStore(repo_path=\".\")\nprint(\"\\n--- Run feast apply ---\")\nsubprocess.run([\"feast\", \"apply\"])\nprint(\"\\n--- Historical features for training ---\")\nfetch_historical_features_entity_df(store, for_batch_scoring=False)\nprint(\"\\n--- Historical features for batch scoring ---\")\nfetch_historical_features_entity_df(store, for_batch_scoring=True)\nprint(\"\\n--- Load features into online store ---\")\nstore.materialize_incremental(end_date=datetime.now())\nprint(\"\\n--- Online features ---\")",
        "detail": "qa_feast_spark",
        "documentation": {}
    },
    {
        "label": "run_demo",
        "kind": 2,
        "importPath": "test_workflow",
        "description": "test_workflow",
        "peekOfCode": "def run_demo():\n    store = FeatureStore(repo_path=\".\")\n    print(\"\\n--- Run feast apply to setup feature store on Snowflake ---\")\n    subprocess.run([\"feast\", \"apply\"])\n    print(\"\\n--- Historical features for training ---\")\n    fetch_historical_features_entity_df(store, for_batch_scoring=False)\n    print(\"\\n--- Historical features for batch scoring ---\")\n    fetch_historical_features_entity_df(store, for_batch_scoring=True)\n    print(\"\\n--- Load features into online store ---\")\n    store.materialize_incremental(end_date=datetime.now())",
        "detail": "test_workflow",
        "documentation": {}
    },
    {
        "label": "fetch_historical_features_entity_df",
        "kind": 2,
        "importPath": "test_workflow",
        "description": "test_workflow",
        "peekOfCode": "def fetch_historical_features_entity_df(store: FeatureStore, for_batch_scoring: bool):\n    # Note: see https://docs.feast.dev/getting-started/concepts/feature-retrieval for more details on how to retrieve\n    # for all entities in the offline store instead\n    entity_df = pd.DataFrame.from_dict(\n        {\n            # entity's join key -> entity values\n            \"driver_id\": [1001, 1002, 1003],\n            # \"event_timestamp\" (reserved key) -> timestamps\n            \"event_timestamp\": [\n                datetime(2021, 4, 12, 10, 59, 42),",
        "detail": "test_workflow",
        "documentation": {}
    },
    {
        "label": "fetch_online_features",
        "kind": 2,
        "importPath": "test_workflow",
        "description": "test_workflow",
        "peekOfCode": "def fetch_online_features(store, use_feature_service: bool):\n    entity_rows = [\n        # {join_key: entity_value}\n        {\n            \"driver_id\": 1001,\n            \"val_to_add\": 1000,\n            \"val_to_add_2\": 2000,\n        },\n        {\n            \"driver_id\": 1002,",
        "detail": "test_workflow",
        "documentation": {}
    }
]